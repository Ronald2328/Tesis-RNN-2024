{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gestor_datos_climaticos import GestorDatosClimaticos\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import device\n",
    "from modelo_lstm import LSTM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el gestor de base de datos\n",
    "ciudad = 'Piura'\n",
    "gestor_db = GestorDatosClimaticos()\n",
    "id_ciudad = gestor_db.obtener_id_ciudad_por_nombre(ciudad)\n",
    "df_clima = gestor_db.obtener_dataframe('clima', id_ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'time' a tipo datetime y extraer mes y día\n",
    "df_clima['time'] = pd.to_datetime(df_clima['time'])\n",
    "df_clima['mes'], df_clima['dia'] = df_clima['time'].dt.month, df_clima['time'].dt.day\n",
    "\n",
    "# Determinar la estación del año\n",
    "def determinar_estacion(mes, dia):\n",
    "    if (mes == 12 and dia >= 1) or mes in [1, 2]: return 'Verano'\n",
    "    if mes in [3, 4, 5]: return 'Otoño'\n",
    "    if mes in [6, 7, 8]: return 'Invierno'\n",
    "    if mes in [9, 10, 11]: return 'Primavera'\n",
    "\n",
    "df_clima['estacion'] = df_clima.apply(lambda row: determinar_estacion(row['mes'], row['dia']), axis=1)\n",
    "\n",
    "# Crear columnas indicadoras para estaciones y meses\n",
    "estaciones_dummies = pd.get_dummies(df_clima['estacion'], drop_first=False).astype(int)\n",
    "meses_dummies = pd.get_dummies(df_clima['mes'], prefix='mes').astype(int)\n",
    "\n",
    "# Agregar las nuevas columnas al DataFrame original\n",
    "df = pd.concat([df_clima, estaciones_dummies, meses_dummies], axis=1)\n",
    "\n",
    "mean_temp_min = df['tmin'].mean()\n",
    "df['tmin'] = df['tmin'].apply(lambda x: mean_temp_min if x < 10 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las características de entrada y las variables de salida\n",
    "features = [col for col in df.columns if col not in ['id_ciudad', 'time', 'snow', 'wpgt', 'tsun','estacion']]\n",
    "\n",
    "features_lstm = [col for col in df.columns if col not in ['id_ciudad', 'time', 'snow', 'wpgt', 'tsun','estacion'\n",
    "                                                     ,'Primavera','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12']] \n",
    "target_features = ['tmax', 'tmin', 'tavg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La data de entrenamiento tiene 1991 filas\n",
      "La data de validación tiene 182 filas\n",
      "La data de testeo tiene 190 filas\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en entrenamiento, validación y testeo\n",
    "df_train = df[df['time'] <= '2023-12-31']\n",
    "df_val = df[(df['time'] > '2023-12-31') & (df['time'] <= '2024-06-30')]\n",
    "df_test = df[df['time'] > '2024-06-30']\n",
    "print(f'La data de entrenamiento tiene {len(df_train)} filas')\n",
    "print(f'La data de validación tiene {len(df_val)} filas')\n",
    "print(f'La data de testeo tiene {len(df_test)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de datos de entrada para modelos no LSTM\n",
    "X_train = df_train[features].values\n",
    "X_val = df_val[features].values\n",
    "X_test = df_test[features].values\n",
    "\n",
    "#Entradas LSTM\n",
    "X_train_lstm = df_train[features_lstm].values \n",
    "X_val_lstm = df_val[features_lstm].values\n",
    "X_test_lstm = df_test[features_lstm].values\n",
    "\n",
    "# Preparación de datos de salida para modelos\n",
    "y_train = df_train[target_features].values\n",
    "y_val = df_val[target_features].values\n",
    "y_test = df_test[target_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros de ventana temporal\n",
    "VENTANA_TIEMPO = 25  # T pasos de tiempo\n",
    "DIMENSION_ENTRADA = len(features)  # Número de características\n",
    "N_ENTRENAMIENTO = len(df_train) - VENTANA_TIEMPO\n",
    "N_VALIDACION = len(df_val) - VENTANA_TIEMPO\n",
    "N_TESTEO = len(df_test) - VENTANA_TIEMPO\n",
    "DIMENSION_SALIDA = 3  # Número de salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de datos (excepto LSTM)\n",
    "normalizador = StandardScaler()\n",
    "normalizador.fit(X_train)\n",
    "\n",
    "# Normalización de los conjuntos de datos\n",
    "X_train = normalizador.transform(X_train)\n",
    "X_val = normalizador.transform(X_val)\n",
    "X_test = normalizador.transform(X_test)\n",
    "\n",
    "# Preparación de datos de entrenamiento con ventana temporal\n",
    "X_entrenamiento = np.zeros((N_ENTRENAMIENTO, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "y_entrenamiento = np.zeros((N_ENTRENAMIENTO, DIMENSION_SALIDA))\n",
    "\n",
    "for t in range(N_ENTRENAMIENTO):\n",
    "    X_entrenamiento[t, :, :] = X_train[t:t + VENTANA_TIEMPO]\n",
    "    y_entrenamiento[t] = y_train[t + VENTANA_TIEMPO]\n",
    "\n",
    "# Preparación de datos de validación con ventana temporal\n",
    "X_validacion = np.zeros((N_VALIDACION, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "y_validacion = np.zeros((N_VALIDACION, DIMENSION_SALIDA))\n",
    "\n",
    "for i in range(N_VALIDACION):\n",
    "    t = i\n",
    "    X_validacion[i, :, :] = X_val[t:t + VENTANA_TIEMPO]\n",
    "    y_validacion[i] = y_val[t + VENTANA_TIEMPO]\n",
    "\n",
    "# Preparación de datos de testeo con ventana temporal\n",
    "X_testeo = np.zeros((N_TESTEO, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "y_testeo = np.zeros((N_TESTEO, DIMENSION_SALIDA))\n",
    "\n",
    "for i in range(N_TESTEO):\n",
    "    t = i\n",
    "    X_testeo[i, :, :] = X_test[t:t + VENTANA_TIEMPO]\n",
    "    y_testeo[i] = y_test[t + VENTANA_TIEMPO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "normalizador_lstm = joblib.load('escalado.pkl')\n",
    "DIMENSION_ENTRADA = len(features_lstm)  # Número de características\n",
    "\n",
    "# Normalizar las entradas LSTM\n",
    "X_train_lstm = normalizador_lstm.transform(df_train[features_lstm].values)\n",
    "X_val_lstm = normalizador_lstm.transform(df_val[features_lstm].values)\n",
    "X_test_lstm = normalizador_lstm.transform(df_test[features_lstm].values)\n",
    "\n",
    "# Preparación de datos de entrenamiento con ventana temporal\n",
    "X_entrenamiento_lstm = np.zeros((N_ENTRENAMIENTO, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "\n",
    "for t in range(N_ENTRENAMIENTO):\n",
    "    X_entrenamiento_lstm[t, :, :] = X_train_lstm[t:t + VENTANA_TIEMPO]\n",
    "\n",
    "# Preparación de datos de validación con ventana temporal\n",
    "X_validacion_lstm = np.zeros((N_VALIDACION, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "\n",
    "for i in range(N_VALIDACION):\n",
    "    X_validacion_lstm[i, :, :] = X_val_lstm[i:i + VENTANA_TIEMPO]\n",
    "\n",
    "# Preparación de datos de testeo con ventana temporal\n",
    "X_testeo_lstm = np.zeros((N_TESTEO, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "\n",
    "for i in range(N_TESTEO):\n",
    "    X_testeo_lstm[i, :, :] = X_test_lstm[i:i + VENTANA_TIEMPO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    'MLP': MLPRegressor(\n",
    "        activation='relu',\n",
    "        alpha=0.01,\n",
    "        hidden_layer_sizes=(64,),\n",
    "        learning_rate='constant',\n",
    "        solver='sgd'\n",
    "    ),\n",
    "    'Linear Regression': MultiOutputRegressor(LinearRegression()),\n",
    "    'Elastic Net': MultiOutputRegressor(ElasticNet(\n",
    "        alpha=0.1,\n",
    "        l1_ratio=0.5\n",
    "    )),\n",
    "    'Decision Tree': MultiOutputRegressor(DecisionTreeRegressor(\n",
    "        max_depth=5,\n",
    "        min_samples_leaf=3,\n",
    "        min_samples_split=3\n",
    "    )),\n",
    "    'Random Forest': MultiOutputRegressor(RandomForestRegressor(\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=3,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=100\n",
    "    )),\n",
    "    'Gradient Boosting': MultiOutputRegressor(GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        n_estimators=50\n",
    "    )),\n",
    "    'XGBoost': MultiOutputRegressor(XGBRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        n_estimators=50\n",
    "    )),\n",
    "    'SVR': MultiOutputRegressor(SVR(\n",
    "        C=0.1,\n",
    "        epsilon=0.2,\n",
    "        kernel='linear'\n",
    "    )),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Cargar modelo LSTM\n",
    "modelo_lstm = LSTM(18,512,1,3)\n",
    "modelo_lstm = torch.load(os.path.join(os.path.join(os.getcwd()),'modelo_completo.pth'))\n",
    "modelo_lstm.eval()\n",
    "print(\"Modelo cargado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo: MLP...\n",
      "Entrenando el modelo: Linear Regression...\n",
      "Entrenando el modelo: Elastic Net...\n",
      "Entrenando el modelo: Decision Tree...\n",
      "Entrenando el modelo: Random Forest...\n",
      "Entrenando el modelo: Gradient Boosting...\n",
      "Entrenando el modelo: XGBoost...\n",
      "Entrenando el modelo: SVR...\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los resultados\n",
    "resultados_modelos = []\n",
    "\n",
    "# Recorrer los modelos\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando el modelo: {nombre}...\")\n",
    "    \n",
    "    # Ajustar el modelo a los datos de entrenamiento\n",
    "    modelo.fit(X_entrenamiento.reshape(N_ENTRENAMIENTO, -1), y_entrenamiento)\n",
    "    \n",
    "    # Realizar predicciones en los datos de entrenamiento, validación y test\n",
    "    y_train_pred = modelo.predict(X_entrenamiento.reshape(N_ENTRENAMIENTO, -1))\n",
    "    y_val_pred = modelo.predict(X_validacion.reshape(N_VALIDACION, -1))\n",
    "    y_test_pred = modelo.predict(X_testeo.reshape(N_TESTEO, -1))\n",
    "    \n",
    "    # Calcular RMSE y MAE para cada conjunto de datos\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_entrenamiento, y_train_pred))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_validacion, y_val_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_testeo, y_test_pred))\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_entrenamiento, y_train_pred)\n",
    "    val_mae = mean_absolute_error(y_validacion, y_val_pred)\n",
    "    test_mae = mean_absolute_error(y_testeo, y_test_pred)\n",
    "    \n",
    "    # Calcular MAPE para cada conjunto de datos, manejando divisiones por cero\n",
    "    train_mape = np.mean(np.abs((y_entrenamiento - y_train_pred) / y_entrenamiento)) * 100\n",
    "    val_mape = np.mean(np.abs((y_validacion - y_val_pred) / y_validacion)) * 100\n",
    "    test_mape = np.mean(np.abs((y_testeo - y_test_pred) / y_testeo)) * 100\n",
    "    \n",
    "    # Calcular el error máximo para cada conjunto de datos\n",
    "    train_max_error = np.max(np.abs(y_entrenamiento - y_train_pred)) if len(y_entrenamiento) > 0 else 0\n",
    "    val_max_error = np.max(np.abs(y_validacion - y_val_pred)) if len(y_validacion) > 0 else 0\n",
    "    test_max_error = np.max(np.abs(y_testeo - y_test_pred)) if len(y_testeo) > 0 else 0\n",
    "    \n",
    "    # Calcular la desviación estándar del error (dispersión) para cada conjunto de datos\n",
    "    train_error_std = np.std(y_entrenamiento - y_train_pred) if len(y_entrenamiento) > 0 else 0\n",
    "    val_error_std = np.std(y_validacion - y_val_pred) if len(y_validacion) > 0 else 0\n",
    "    test_error_std = np.std(y_testeo - y_test_pred) if len(y_testeo) > 0 else 0\n",
    "    \n",
    "    # Almacenar los resultados\n",
    "    resultados_modelos.append({\n",
    "        'Modelo': nombre,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Val RMSE': val_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Val MAE': val_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Train MAPE': train_mape,\n",
    "        'Val MAPE': val_mape,\n",
    "        'Test MAPE': test_mape,\n",
    "        'Train Max Error': train_max_error,\n",
    "        'Val Max Error': val_max_error,\n",
    "        'Test Max Error': test_max_error,\n",
    "        'Train Error Std': train_error_std,\n",
    "        'Val Error Std': val_error_std,\n",
    "        'Test Error Std': test_error_std\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entrenando el modelo: LSTM...\")\n",
    "modelo_lstm.eval() \n",
    "\n",
    "with torch.no_grad():  # Desactiva gradientes para evaluación\n",
    "    # Predicciones para los conjuntos de entrenamiento, validación y test\n",
    "    y_train_pred = modelo_lstm(torch.tensor(X_entrenamiento_lstm, dtype=torch.float32)).squeeze(-1).numpy()\n",
    "    y_val_pred = modelo_lstm(torch.tensor(X_validacion_lstm, dtype=torch.float32)).squeeze(-1).numpy()\n",
    "    y_test_pred = modelo_lstm(torch.tensor(X_testeo_lstm, dtype=torch.float32)).squeeze(-1).numpy()\n",
    "\n",
    "# Calcular métricas\n",
    "train_rmse = np.sqrt(mean_squared_error(y_entrenamiento, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_validacion, y_val_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_testeo, y_test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_entrenamiento, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_validacion, y_val_pred)\n",
    "test_mae = mean_absolute_error(y_testeo, y_test_pred)\n",
    "\n",
    "# Calcular MAPE \n",
    "train_mape = np.mean(np.abs((y_entrenamiento - y_train_pred) / y_entrenamiento)) * 100\n",
    "val_mape = np.mean(np.abs((y_validacion - y_val_pred) / y_validacion)) * 100\n",
    "test_mape = np.mean(np.abs((y_testeo - y_test_pred) / y_testeo)) * 100\n",
    "\n",
    "# Calcular error máximo\n",
    "train_max_error = np.max(np.abs(y_entrenamiento - y_train_pred)) \n",
    "val_max_error = np.max(np.abs(y_validacion - y_val_pred)) \n",
    "test_max_error = np.max(np.abs(y_testeo - y_test_pred))\n",
    "\n",
    "# Calcular la desviación estándar del error (dispersión)\n",
    "train_error_std = np.std(y_entrenamiento - y_train_pred) \n",
    "val_error_std = np.std(y_validacion - y_val_pred)\n",
    "test_error_std = np.std(y_testeo - y_test_pred)\n",
    "\n",
    "# Almacenar los resultados en el diccionario\n",
    "resultados_modelos.append({\n",
    "    'Modelo': 'LSTM',\n",
    "    'Train RMSE': train_rmse,\n",
    "    'Val RMSE': val_rmse,\n",
    "    'Test RMSE': test_rmse,\n",
    "    'Train MAE': train_mae,\n",
    "    'Val MAE': val_mae,\n",
    "    'Test MAE': test_mae,\n",
    "    'Train MAPE': train_mape,\n",
    "    'Val MAPE': val_mape,\n",
    "    'Test MAPE': test_mape,\n",
    "    'Train Max Error': train_max_error,\n",
    "    'Val Max Error': val_max_error,\n",
    "    'Test Max Error': test_max_error,\n",
    "    'Train Error Std': train_error_std,\n",
    "    'Val Error Std': val_error_std,\n",
    "    'Test Error Std': test_error_std\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Val RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Val MAE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Val MAPE</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Train Max Error</th>\n",
       "      <th>Val Max Error</th>\n",
       "      <th>Test Max Error</th>\n",
       "      <th>Train Error Std</th>\n",
       "      <th>Val Error Std</th>\n",
       "      <th>Test Error Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.654</td>\n",
       "      <td>1.175</td>\n",
       "      <td>0.859</td>\n",
       "      <td>2.707</td>\n",
       "      <td>4.826</td>\n",
       "      <td>3.616</td>\n",
       "      <td>5.336</td>\n",
       "      <td>6.285</td>\n",
       "      <td>5.011</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.576</td>\n",
       "      <td>1.710</td>\n",
       "      <td>1.323</td>\n",
       "      <td>0.437</td>\n",
       "      <td>1.346</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.855</td>\n",
       "      <td>5.499</td>\n",
       "      <td>4.173</td>\n",
       "      <td>3.359</td>\n",
       "      <td>5.969</td>\n",
       "      <td>5.466</td>\n",
       "      <td>0.575</td>\n",
       "      <td>1.703</td>\n",
       "      <td>1.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.762</td>\n",
       "      <td>1.532</td>\n",
       "      <td>1.220</td>\n",
       "      <td>0.579</td>\n",
       "      <td>1.138</td>\n",
       "      <td>0.886</td>\n",
       "      <td>2.400</td>\n",
       "      <td>4.697</td>\n",
       "      <td>3.737</td>\n",
       "      <td>4.384</td>\n",
       "      <td>5.739</td>\n",
       "      <td>5.375</td>\n",
       "      <td>0.762</td>\n",
       "      <td>1.531</td>\n",
       "      <td>1.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.485</td>\n",
       "      <td>1.122</td>\n",
       "      <td>0.656</td>\n",
       "      <td>1.101</td>\n",
       "      <td>0.803</td>\n",
       "      <td>2.719</td>\n",
       "      <td>4.565</td>\n",
       "      <td>3.372</td>\n",
       "      <td>5.623</td>\n",
       "      <td>6.012</td>\n",
       "      <td>5.248</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.484</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.671</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.216</td>\n",
       "      <td>0.874</td>\n",
       "      <td>2.687</td>\n",
       "      <td>5.006</td>\n",
       "      <td>3.668</td>\n",
       "      <td>4.251</td>\n",
       "      <td>6.479</td>\n",
       "      <td>6.071</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.558</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.114</td>\n",
       "      <td>0.817</td>\n",
       "      <td>1.188</td>\n",
       "      <td>4.620</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.363</td>\n",
       "      <td>6.340</td>\n",
       "      <td>5.225</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.558</td>\n",
       "      <td>1.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1.536</td>\n",
       "      <td>1.132</td>\n",
       "      <td>0.566</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.797</td>\n",
       "      <td>2.345</td>\n",
       "      <td>4.648</td>\n",
       "      <td>3.329</td>\n",
       "      <td>3.751</td>\n",
       "      <td>6.290</td>\n",
       "      <td>5.335</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.754</td>\n",
       "      <td>1.542</td>\n",
       "      <td>1.122</td>\n",
       "      <td>0.566</td>\n",
       "      <td>1.126</td>\n",
       "      <td>0.796</td>\n",
       "      <td>2.347</td>\n",
       "      <td>4.650</td>\n",
       "      <td>3.323</td>\n",
       "      <td>4.314</td>\n",
       "      <td>6.228</td>\n",
       "      <td>5.446</td>\n",
       "      <td>0.754</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.801</td>\n",
       "      <td>1.509</td>\n",
       "      <td>1.229</td>\n",
       "      <td>0.559</td>\n",
       "      <td>1.119</td>\n",
       "      <td>0.888</td>\n",
       "      <td>2.322</td>\n",
       "      <td>4.611</td>\n",
       "      <td>3.741</td>\n",
       "      <td>5.458</td>\n",
       "      <td>5.686</td>\n",
       "      <td>5.352</td>\n",
       "      <td>0.801</td>\n",
       "      <td>1.509</td>\n",
       "      <td>1.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo  Train RMSE  Val RMSE  Test RMSE  Train MAE  Val MAE  \\\n",
       "0               LSTM       0.881     1.582      1.176      0.654    1.175   \n",
       "1                MLP       0.576     1.710      1.323      0.437    1.346   \n",
       "2  Linear Regression       0.762     1.532      1.220      0.579    1.138   \n",
       "3        Elastic Net       0.881     1.485      1.122      0.656    1.101   \n",
       "4      Decision Tree       0.852     1.671      1.224      0.647    1.216   \n",
       "5      Random Forest       0.416     1.558      1.139      0.287    1.114   \n",
       "6  Gradient Boosting       0.746     1.536      1.132      0.566    1.125   \n",
       "7            XGBoost       0.754     1.542      1.122      0.566    1.126   \n",
       "8                SVR       0.801     1.509      1.229      0.559    1.119   \n",
       "\n",
       "   Test MAE  Train MAPE  Val MAPE  Test MAPE  Train Max Error  Val Max Error  \\\n",
       "0     0.859       2.707     4.826      3.616            5.336          6.285   \n",
       "1     0.990       1.855     5.499      4.173            3.359          5.969   \n",
       "2     0.886       2.400     4.697      3.737            4.384          5.739   \n",
       "3     0.803       2.719     4.565      3.372            5.623          6.012   \n",
       "4     0.874       2.687     5.006      3.668            4.251          6.479   \n",
       "5     0.817       1.188     4.620      3.422            3.363          6.340   \n",
       "6     0.797       2.345     4.648      3.329            3.751          6.290   \n",
       "7     0.796       2.347     4.650      3.323            4.314          6.228   \n",
       "8     0.888       2.322     4.611      3.741            5.458          5.686   \n",
       "\n",
       "   Test Max Error  Train Error Std  Val Error Std  Test Error Std  \n",
       "0           5.011            0.881          1.575           1.161  \n",
       "1           5.466            0.575          1.703           1.318  \n",
       "2           5.375            0.762          1.531           1.214  \n",
       "3           5.248            0.881          1.484           1.118  \n",
       "4           6.071            0.852          1.667           1.210  \n",
       "5           5.225            0.416          1.558           1.129  \n",
       "6           5.335            0.746          1.534           1.129  \n",
       "7           5.446            0.754          1.539           1.118  \n",
       "8           5.352            0.801          1.509           1.226  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(resultados_modelos)\n",
    "df = df.round(3)\n",
    "df = pd.concat([df[df['Modelo'] == 'LSTM'], df[df['Modelo'] != 'LSTM']], ignore_index=True)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
