{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gestor_datos_climaticos import GestorDatosClimaticos\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import device\n",
    "from modelo_lstm import LSTM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluadorModelo:\n",
    "    def __init__(self):\n",
    "        self.resultados = pd.DataFrame(columns=['Modelo', 'MAE_Entrenamiento', 'RMSE_Entrenamiento', 'MSE_Entrenamiento', 'R_Entrenamiento', \n",
    "                                              'MAE_Validacion', 'RMSE_Validacion', 'MSE_Validacion', 'R_Validacion'])\n",
    "\n",
    "    def evaluar_modelo(self, modelo, X_entrenamiento, y_entrenamiento, X_validacion, y_validacion):\n",
    "        # Entrenar el modelo\n",
    "        modelo.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "        # Hacer predicciones\n",
    "        predicciones_entrenamiento = modelo.predict(X_entrenamiento)\n",
    "        predicciones_validacion = modelo.predict(X_validacion)\n",
    "\n",
    "        # Calcular métricas\n",
    "        mae_entrenamiento = mean_absolute_error(y_entrenamiento, predicciones_entrenamiento)\n",
    "        rmse_entrenamiento = np.sqrt(mean_squared_error(y_entrenamiento, predicciones_entrenamiento))\n",
    "        mse_entrenamiento = mean_squared_error(y_entrenamiento, predicciones_entrenamiento)\n",
    "        r_entrenamiento = r2_score(y_entrenamiento, predicciones_entrenamiento)\n",
    "\n",
    "        mae_validacion = mean_absolute_error(y_validacion, predicciones_validacion)\n",
    "        rmse_validacion = np.sqrt(mean_squared_error(y_validacion, predicciones_validacion))\n",
    "        mse_validacion = mean_squared_error(y_validacion, predicciones_validacion)\n",
    "        r_validacion = r2_score(y_validacion, predicciones_validacion)\n",
    "\n",
    "        # Obtener el nombre del modelo base\n",
    "        nombre_modelo = modelo.estimator.__class__.__name__ if hasattr(modelo, 'estimator') else modelo.__class__.__name__\n",
    "\n",
    "        # Agregar resultados al DataFrame\n",
    "        nueva_fila = pd.DataFrame({\n",
    "            'Modelo': [nombre_modelo],\n",
    "            'MAE_Entrenamiento': [mae_entrenamiento],\n",
    "            'RMSE_Entrenamiento': [rmse_entrenamiento],\n",
    "            'MSE_Entrenamiento': [mse_entrenamiento],\n",
    "            'R_Entrenamiento': [r_entrenamiento],\n",
    "            'MAE_Validacion': [mae_validacion],\n",
    "            'RMSE_Validacion': [rmse_validacion],\n",
    "            'MSE_Validacion': [mse_validacion],\n",
    "            'R_Validacion': [r_validacion]\n",
    "        })\n",
    "        self.resultados = pd.concat([self.resultados, nueva_fila], ignore_index=True)\n",
    "\n",
    "    def evaluar_lstm(self, modelo, X_entrenamiento, y_entrenamiento, X_validacion, y_validacion, epocas=100, intervalo=100):\n",
    "        # Asegúrate de que los datos estén en el formato correcto\n",
    "        tensor_X_entrenamiento = torch.tensor(X_entrenamiento, dtype=torch.float32).to(device)\n",
    "        tensor_y_entrenamiento = torch.tensor(y_entrenamiento, dtype=torch.float32).to(device)\n",
    "        tensor_X_validacion = torch.tensor(X_validacion, dtype=torch.float32).to(device)\n",
    "        tensor_y_validacion = torch.tensor(y_validacion, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        historial = entrenar(modelo, 0.01, tensor_X_entrenamiento, tensor_y_entrenamiento, \n",
    "                           tensor_X_validacion, tensor_y_validacion, epocas=epocas, intervalo=intervalo)\n",
    "\n",
    "        # Hacer predicciones\n",
    "        modelo.eval()\n",
    "        with torch.no_grad():\n",
    "            predicciones_entrenamiento = modelo(tensor_X_entrenamiento)\n",
    "            predicciones_validacion = modelo(tensor_X_validacion)\n",
    "\n",
    "        # Calcular métricas\n",
    "        mae_entrenamiento = torch.mean(torch.abs(predicciones_entrenamiento - tensor_y_entrenamiento)).item()\n",
    "        rmse_entrenamiento = torch.sqrt(torch.mean((predicciones_entrenamiento - tensor_y_entrenamiento) ** 2)).item()\n",
    "        mse_entrenamiento = torch.mean((predicciones_entrenamiento - tensor_y_entrenamiento) ** 2).item()\n",
    "        r_entrenamiento = r2_score(tensor_y_entrenamiento.cpu(), predicciones_entrenamiento.cpu())\n",
    "\n",
    "        mae_validacion = torch.mean(torch.abs(predicciones_validacion - tensor_y_validacion)).item()\n",
    "        rmse_validacion = torch.sqrt(torch.mean((predicciones_validacion - tensor_y_validacion) ** 2)).item()\n",
    "        mse_validacion = torch.mean((predicciones_validacion - tensor_y_validacion) ** 2).item()\n",
    "        r_validacion = r2_score(tensor_y_validacion.cpu(), predicciones_validacion.cpu())\n",
    "\n",
    "        # Agregar resultados al DataFrame\n",
    "        nueva_fila = pd.DataFrame({\n",
    "            'Modelo': ['LSTM'],\n",
    "            'MAE_Entrenamiento': [mae_entrenamiento],\n",
    "            'RMSE_Entrenamiento': [rmse_entrenamiento],\n",
    "            'MSE_Entrenamiento': [mse_entrenamiento],\n",
    "            'R_Entrenamiento': [r_entrenamiento],\n",
    "            'MAE_Validacion': [mae_validacion],\n",
    "            'RMSE_Validacion': [rmse_validacion],\n",
    "            'MSE_Validacion': [mse_validacion],\n",
    "            'R_Validacion': [r_validacion]\n",
    "        })\n",
    "        self.resultados = pd.concat([self.resultados, nueva_fila], ignore_index=True)\n",
    "\n",
    "    def mostrar_resultados(self):\n",
    "        # Redondear las columnas numéricas a 3 decimales\n",
    "        print(self.resultados.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La última fecha registrada en la tabla 'clima' para Piura es: 2024-12-26 00:00:00\n",
      "\n",
      "La base de datos ya está actualizada para la ciudad Piura. No es necesario actualizar los datos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el gestor de base de datos\n",
    "ciudad = 'Piura'\n",
    "gestor_db = GestorDatosClimaticos()\n",
    "gestor_db.actualizar_datos_climaticos(ciudad)\n",
    "id_ciudad = gestor_db.obtener_id_ciudad_por_nombre(ciudad)\n",
    "\n",
    "# Obtener y procesar datos\n",
    "df_clima = gestor_db.obtener_dataframe('clima', id_ciudad)\n",
    "df_clima = df_clima.dropna(axis=1, how='all')\n",
    "df_clima['fecha'] = pd.to_datetime(df_clima['time'])\n",
    "df_clima['mes'] = df_clima['fecha'].dt.month\n",
    "\n",
    "# Crear variables dummy para meses\n",
    "meses_codificados = pd.get_dummies(df_clima['mes'], prefix='mes').astype(int)\n",
    "df_clima = pd.concat([df_clima, meses_codificados], axis=1)\n",
    "df_clima.drop('mes', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La data de entrenamiento tiene 1991 filas\n",
      "La data de validación tiene 182 filas\n"
     ]
    }
   ],
   "source": [
    "# Definir características de entrada y variables objetivo\n",
    "caracteristicas = [col for col in df_clima.columns if col not in ['id_ciudad', 'time','snow', 'wpgt', 'tsun', 'fecha']]\n",
    "variables_objetivo = ['tmax', 'tmin', 'tavg']\n",
    "\n",
    "# División temporal de datos\n",
    "df_entrenamiento = df_clima[df_clima['time'] <= '2023-12-31']\n",
    "df_validacion = df_clima[(df_clima['time'] > '2023-12-31') & (df_clima['time'] <= '2024-06-30')]\n",
    "print(f'La data de entrenamiento tiene {len(df_entrenamiento)} filas')\n",
    "print(f'La data de validación tiene {len(df_validacion)} filas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de datos de entrada y salida\n",
    "datos_entrada_entrenamiento = df_entrenamiento[caracteristicas].values\n",
    "datos_entrada_validacion = df_validacion[caracteristicas].values\n",
    "objetivos_entrenamiento = df_entrenamiento[variables_objetivo].values\n",
    "objetivos_validacion = df_validacion[variables_objetivo].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros de ventana temporal\n",
    "VENTANA_TIEMPO = 20  # T pasos de tiempo\n",
    "DIMENSION_ENTRADA = datos_entrada_entrenamiento.shape[1]\n",
    "N_ENTRENAMIENTO = len(datos_entrada_entrenamiento) - VENTANA_TIEMPO\n",
    "N_VALIDACION = len(datos_entrada_validacion) - VENTANA_TIEMPO\n",
    "DIMENSION_SALIDA = len(variables_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de datos\n",
    "normalizador = StandardScaler()\n",
    "# Excluir columnas de fecha antes de la normalización\n",
    "normalizador.fit(datos_entrada_entrenamiento[:len(datos_entrada_entrenamiento) + VENTANA_TIEMPO - 1])\n",
    "datos_entrada_entrenamiento = normalizador.transform(datos_entrada_entrenamiento)\n",
    "datos_entrada_validacion = normalizador.transform(datos_entrada_validacion)\n",
    "\n",
    "# Preparación de datos de entrenamiento\n",
    "X_entrenamiento = np.zeros((N_ENTRENAMIENTO, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "y_entrenamiento = np.zeros((N_ENTRENAMIENTO, DIMENSION_SALIDA))\n",
    "\n",
    "for t in range(N_ENTRENAMIENTO):\n",
    "    X_entrenamiento[t, :, :] = datos_entrada_entrenamiento[t:t+VENTANA_TIEMPO]\n",
    "    y_entrenamiento[t] = objetivos_entrenamiento[t+VENTANA_TIEMPO]\n",
    "\n",
    "# Preparación de datos de validación\n",
    "X_validacion = np.zeros((N_VALIDACION, VENTANA_TIEMPO, DIMENSION_ENTRADA))\n",
    "y_validacion = np.zeros((N_VALIDACION, DIMENSION_SALIDA))\n",
    "\n",
    "for i in range(N_VALIDACION):\n",
    "    t = i\n",
    "    X_validacion[i, :, :] = datos_entrada_validacion[t:t+VENTANA_TIEMPO]\n",
    "    y_validacion[i] = objetivos_validacion[t+VENTANA_TIEMPO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    'MLP': MLPRegressor(\n",
    "        activation='relu',\n",
    "        alpha=0.01,\n",
    "        hidden_layer_sizes=(64,),\n",
    "        learning_rate='constant',\n",
    "        solver='sgd'\n",
    "    ),\n",
    "    'Linear Regression': MultiOutputRegressor(LinearRegression()),\n",
    "    'Elastic Net': MultiOutputRegressor(ElasticNet(\n",
    "        alpha=0.1,\n",
    "        l1_ratio=0.5\n",
    "    )),\n",
    "    'Decision Tree': MultiOutputRegressor(DecisionTreeRegressor(\n",
    "        max_depth=5,\n",
    "        min_samples_leaf=3,\n",
    "        min_samples_split=3\n",
    "    )),\n",
    "    'Random Forest': MultiOutputRegressor(RandomForestRegressor(\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=3,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=100\n",
    "    )),\n",
    "    'Gradient Boosting': MultiOutputRegressor(GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        n_estimators=50\n",
    "    )),\n",
    "    'XGBoost': MultiOutputRegressor(XGBRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        n_estimators=50\n",
    "    )),\n",
    "    'SVR': MultiOutputRegressor(SVR(\n",
    "        C=0.1,\n",
    "        epsilon=0.2,\n",
    "        kernel='linear'\n",
    "    )),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(19, 256, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurar dispositivo\n",
    "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Dimensiones del modelo\n",
    "dimension_entrada = len(caracteristicas)      # Número de características de entrada\n",
    "dimension_oculta = 256                        # Dimensión de las capas ocultas\n",
    "numero_capas = 1                              # Número de capas LSTM\n",
    "dimension_salida = len(variables_objetivo)    # Número de variables a predecir\n",
    "prob_dropout = 0.2                            # Probabilidad de desactivación de neuronas\n",
    "\n",
    "# Crear y configurar el modelo LSTM\n",
    "modelo = LSTM(dimension_entrada, dimension_oculta, numero_capas, dimension_salida, prob_dropout)\n",
    "\n",
    "# Mover modelo al dispositivo de procesamiento\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEntrenando Modelo LSTM TOTAL\u001b[0m: 100%|█████████████████████████████████████████████████| 300/300 epocas\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Época 300/300:\n",
      "Train Loss: 0.909, Val Loss: 2.187\n",
      "Train MAE: 0.686, Val MAE: 1.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Modelo  MAE_Entrenamiento  RMSE_Entrenamiento  \\\n",
      "0                       LSTM              0.685               0.953   \n",
      "1               MLPRegressor              0.443               0.610   \n",
      "2           LinearRegression              0.610               0.834   \n",
      "3                 ElasticNet              0.667               0.931   \n",
      "4      DecisionTreeRegressor              0.658               0.891   \n",
      "5      RandomForestRegressor              0.294               0.468   \n",
      "6  GradientBoostingRegressor              0.573               0.755   \n",
      "7               XGBRegressor              0.576               0.767   \n",
      "8                        SVR              0.589               0.871   \n",
      "\n",
      "   MSE_Entrenamiento  R_Entrenamiento  MAE_Validacion  RMSE_Validacion  \\\n",
      "0              0.909            0.866           1.132            1.479   \n",
      "1              0.372            0.946           1.452            1.855   \n",
      "2              0.696            0.897           1.110            1.497   \n",
      "3              0.866            0.872           1.087            1.466   \n",
      "4              0.794            0.882           1.237            1.698   \n",
      "5              0.219            0.968           1.098            1.540   \n",
      "6              0.570            0.915           1.121            1.544   \n",
      "7              0.588            0.912           1.115            1.530   \n",
      "8              0.759            0.888           1.104            1.488   \n",
      "\n",
      "   MSE_Validacion  R_Validacion  \n",
      "0           2.187         0.771  \n",
      "1           3.440         0.634  \n",
      "2           2.242         0.763  \n",
      "3           2.150         0.774  \n",
      "4           2.882         0.698  \n",
      "5           2.371         0.753  \n",
      "6           2.385         0.752  \n",
      "7           2.342         0.756  \n",
      "8           2.214         0.766  \n"
     ]
    }
   ],
   "source": [
    "# Reshape de datos para modelos tradicionales\n",
    "X_entrenamiento_2D = X_entrenamiento.reshape(X_entrenamiento.shape[0], -1)\n",
    "X_validacion_2D = X_validacion.reshape(X_validacion.shape[0], -1)\n",
    "\n",
    "# Crear instancia del evaluador de modelos\n",
    "evaluador = EvaluadorModelo()\n",
    "\n",
    "# Evaluar modelo LSTM\n",
    "evaluador.evaluar_lstm(modelo, X_entrenamiento, y_entrenamiento, \n",
    "                      X_validacion, y_validacion, epocas=300, intervalo=300)\n",
    "\n",
    "# Evaluar modelos tradicionales\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    evaluador.evaluar_modelo(modelo, X_entrenamiento_2D, y_entrenamiento, \n",
    "                           X_validacion_2D, y_validacion)\n",
    "\n",
    "# Mostrar resultados comparativos\n",
    "evaluador.mostrar_resultados()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
